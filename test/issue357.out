listen
    type linemode
        2003 proto tcp
        2003 proto udp
        /tmp/.s.carbon-c-relay.2003 proto unix
    ;

statistics
    submit every 60 seconds
    prefix with carbon.relays.test_hostname
    ;

cluster clickhouse
    failover
        127.0.0.1:2113
        127.0.0.1:2123
        127.0.0.1:2133
    ;

match *
    validate ^[0-9.eE+-]+\ [0-9]{10}$ else drop
    ;
match BTest.system.Kafka.Study.
    send to blackhole
    stop
    ;
match BTest.NetworkServices..*.PartnersGateway.Requests._
    send to blackhole
    stop
    ;
match Ddoc.Cassandra.._.._.ColumnFamily.system.
    send to blackhole
    stop
    ;
match DdocTest.Cassandra.._.._.ColumnFamily.system.
    send to blackhole
    stop
    ;
match Ddoc.Cassandra.._.._.ColumnFamily.system_auth.
    send to blackhole
    stop
    ;
match DdocTest.Cassandra.._.._.ColumnFamily.system_auth.
    send to blackhole
    stop
    ;
match Ddoc.Cassandra.._.._.ColumnFamily.system_distributed.
    send to blackhole
    stop
    ;
match DdocTest.Cassandra.._.._.ColumnFamily.system_distributed.
    send to blackhole
    stop
    ;
match Ddoc.Cassandra.._.._.ColumnFamily.system_traces.
    send to blackhole
    stop
    ;
match DdocTest.Cassandra.._.._.ColumnFamily.system_traces.
    send to blackhole
    stop
    ;
aggregate ^(Al|AlTest|B|DevOps|Ddoc|ED|EDTest|FM|FMTest|KOF|Infra|Infra-dev|Infra-cloud|KOF-test|Cabinet|MEI|MEITest).Cassandra.([^.]+).([^.]+).ColumnFamily.([^.]+).([^.]+).(ReadLatency|WriteLatency).(FifteenMinuteRate|FiveMinuteRate|OneMinuteRate)$
    every 60 seconds
    expire after 75 seconds
    timestamp at start of bucket
    compute sum write to
        \1.Cassandra.\2.\3.ColumnFamily.TOTAL.\6.\7
    ;
aggregate ^DB.([a-zA-Z-]+).([a-zA-Z]+).cassandra.([^.]+).([^.]+).ColumnFamily.([^.]+).([^.]+).(ReadLatency|WriteLatency).(FifteenMinuteRate|FiveMinuteRate|OneMinuteRate)$
    every 60 seconds
    expire after 75 seconds
    timestamp at start of bucket
    compute sum write to
        DB.\1.\2.cassandra.\3.\4.ColumnFamily.TOTAL.\7.\8
    ;
match ^ED.SubSystem.SlaMonitoring.
    send to clickhouse
    ;
match ^KF(-cloud|-dev|-load-cloud|-load-cloud-infra)?.(zero|zero-global|kstor|banana|elasticsearch).
    send to clickhouse
    ;
match ^LDS(_DEMO|_TEST)?.diamond.
    send to clickhouse
    ;
match ^merc(-cloud)?.sync.operations.errors.by.entity.count.
    send to clickhouse
    ;
match [0-9A-Fa-f]{8}-?[0-9A-Fa-f]{4}-?[0-9A-Fa-f]{4}-?[0-9A-Fa-f]{4}-?[0-9A-Fa-f]{12}
    send to blackhole
    stop
    ;
match *
    send to clickhouse
    ;
aggregate IFD.Production.ifd-documents-sender.[A-Za-z0-9-]+.timeline.events.[A-Za-z0-9-]+.[0-9]+.errors.Last-Errors
    every 60 seconds
    expire after 75 seconds
    timestamp at end of bucket
    compute sum write to
        IFD.Production.ifd-documents-senderSUM.SENDER2.timeline.events.HOST.ALL.errors.Last-Errors
    ;
match ^IFD.Production.ifd-fns-documents-senderSUM.SENDER2.timeline.events.HOST.ALL.errors.Last-Errors
    send to clickhouse
    stop
    ;
aggregate IFD.Production.ifd-message-service.([A-Za-z0-9-]+).timeline.events.([A-Za-z0-9-]+).([0-9]+).errors.Last-Errors
    every 60 seconds
    expire after 75 seconds
    timestamp at start of bucket
    compute average write to
        IFD.Production.ifd-message-serviceAVG.\1.timeline.events.\2.\3.errors.Last-Errors
    ;
aggregate IFD.Production.ifd-message-serviceAVG.([A-Za-z0-9-]+).timeline.events.([A-Za-z0-9-]+).([0-9]+).errors.Last-Errors
    every 60 seconds
    expire after 75 seconds
    timestamp at start of bucket
    compute sum write to
        IFD.Production.ifd-message-serviceSUM.SENDER2.timeline.events.HOST.ALL.errors.Last-Errors
    ;
match IFD.Production.ifd-message-serviceSUM.SENDER2.timeline.events.HOST.ALL.errors.Last-Errors
    send to clickhouse
    stop
    ;
aggregate Windows.([A-Za-z0-9_-]+).system.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).process.agent.threadcount
    every 60 seconds
    expire after 75 seconds
    timestamp at start of bucket
    compute average write to
        WindowsAVG.Project.system.Group.\3.process.agent.threadcount
    ;
aggregate Windows.Project.system.Group.([A-Za-z0-9_-]+).process.agent.threadcount
    every 60 seconds
    expire after 75 seconds
    timestamp at start of bucket
    compute sum write to
        WindowsSUM2.Project.system.Group.Hosts.process.agent.threadcount
    ;
match WindowsSUM2.Project.system.Group.Hosts.process.agent.threadcount
    send to clickhouse
    stop
    ;
aggregate Windows.([A-Za-z0-9_-]+).system.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).process.agent.workingset
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute average write to
        WindowsAVG.\1.system.\2.HOST.process.agent.workingset
    ;
aggregate WindowsAVG.([A-Za-z0-9_-]+).system.([A-Za-z0-9_-]+).HOST.process.agent.workingset
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        WindowsSUM2.Project.system.Group.Hosts.process.agent.workingset
    ;
match WindowsSUM2.Project.system.Group.Hosts.process.agent.workingset
    send to clickhouse
    stop
    ;
rewrite Windows.([A-Za-z0-9_-]+).system.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).process.agent.threadcount
    into WindowsTOP.\1.system.\2.\3.process.agent.threadcount
    ;
match WindowsTOP.([A-Za-z0-9_-]+).system.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).process.agent.threadcount
    validate ^([5-9]{1}[0-9]{1})\ ([0-9]+)$ else drop
    send to clickhouse
    stop
    ;
rewrite DM.Kafka.Production.([A-Za-z0-9_-]+).kafka.server.BrokerTopicMetrics.topic.([A-Za-z0-9_-]+).MessagesInPerSec.count
    into DM.Kafka.Production.\1.kafka.server.BrokerTopicMetrics.topic.\2.MessagesInPerSec.countAboveZero
    ;
match DM.Kafka.Production.([A-Za-z0-9_-]+).kafka.server.BrokerTopicMetrics.topic.([A-Za-z0-9_-]+).MessagesInPerSec.countAboveZero
    validate ^([1-9]{1,})\ ([0-9]+)$ else drop
    send to clickhouse
    stop
    ;
rewrite DM.Kafka.Production.([A-Za-z0-9_-]+).kafka.server.BrokerTopicMetrics.topic.([A-Za-z0-9_-]+).BytesInPerSec.count
    into DM.Kafka.Production.\1.kafka.server.BrokerTopicMetrics.topic.\2.BytesInPerSec.countAboveZero
    ;
match DM.Kafka.Production.([A-Za-z0-9_-]+).kafka.server.BrokerTopicMetrics.topic.([A-Za-z0-9_-]+).BytesInPerSec.countAboveZero
    validate ^([1-9]{1,})\ ([0-9]+)$ else drop
    send to clickhouse
    stop
    ;
rewrite DM.Kafka.Production.([A-Za-z0-9_-]+).kafka.server.BrokerTopicMetrics.topic.([A-Za-z0-9_-]+).BytesOutPerSec.count
    into DM.Kafka.Production.\1.kafka.server.BrokerTopicMetrics.topic.\2.BytesOutPerSec.countAboveZero
    ;
match DM.Kafka.Production.([A-Za-z0-9_-]+).kafka.server.BrokerTopicMetrics.topic.([A-Za-z0-9_-]+).BytesOutPerSec.countAboveZero
    validate ^([1-9]{1,})\ ([0-9]+)$ else drop
    send to clickhouse
    stop
    ;
aggregate KE.kstor.global.cs.logicalChunkVolume.([A-Za-z0-9_-]+)
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        KE.kstor3d.global.cs.logicalChunkVolumeSUM2.HOSTS
    ;
match KE.kstor3d.global.cs.logicalChunkVolumeSUM2.HOSTS
    send to clickhouse
    stop
    ;
aggregate KE.kstor3d.global.cs.physicalChunkVolume.([A-Za-z0-9_-]+)
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        KE.kstor3d.global.cs.physicalChunkVolumeSUM2.HOSTS
    ;
match KE.kstor.global.cs.physicalChunkVolumeSUM2.HOSTS
    send to clickhouse
    stop
    ;
aggregate KE.houston.host.storage.logs.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).([0-9]+)
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        KE.houston.host.storage.logsSUM.\1.SUM2
    ;
match KE.houston.host.storage.logsSUM.([A-Za-z0-9_-]+).SUM2
    send to clickhouse
    stop
    ;
aggregate KE.houston.host.storage.logs.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).([0-9]+)
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        KE.houston.host.storage.logsSUM.HOST.\2.SUM2
    ;
match KE.houston.host.storage.logsSUM.HOST.([A-Za-z0-9_-]+).SUM2
    send to clickhouse
    stop
    ;
aggregate KE-cloud.houston.host.storage.logs.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).([0-9]+)
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        KE-cloud.houston.host.storage.logsSUM.\1.SUM2
    ;
match KE-cloud.houston.host.storage.logsSUM.([A-Za-z0-9_-]+).SUM2
    send to clickhouse
    stop
    ;
aggregate KE-cloud.houston.host.storage.logs.([A-Za-z0-9_-]+).([A-Za-z0-9_-]+).([0-9]+)
    every 60 seconds
    expire after 90 seconds
    timestamp at start of bucket
    compute sum write to
        KE-cloud.houston.host.storage.logsSUM.HOST.\2.SUM2
    ;
match KE-cloud.houston.host.storage.logsSUM.HOST.([A-Za-z0-9_-]+).SUM2
    send to clickhouse
    stop
    ;

